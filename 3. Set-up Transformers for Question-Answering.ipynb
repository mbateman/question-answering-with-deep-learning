{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4ae722",
   "metadata": {},
   "source": [
    "# M1 Extracting Paragraphs from the EU Taxonomy Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bafd6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import textract\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9afb7",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Process the EU sustainable finance taxonomy PDF file and extract and clean all the paragraphs in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f7ca7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Download the EU sustainable finance taxonomy PDF from Taxonomy Report: Technical Annex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbab343",
   "metadata": {},
   "source": [
    "## Load the EU sustainable finance taxonomy PDF file using the textract library and decode it. \n",
    "\n",
    "Look through the text to ensure that you have got all the text and that the decoding did not produce any bad characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52dfc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = textract.process('EUtaxonomy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c5902a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "167913a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = textract.process('EUtaxonomy.pdf', method='pdfminer').decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d1a94",
   "metadata": {},
   "source": [
    "## Use regular expressions to split the paragraphs and clean the text. \n",
    "\n",
    "The loaded text will be in raw format and will need to be segmented into paragraphs. These paragraphs will also need to be cleaned by removing newline characters and other characters that do not bring any semantic value to the paragraph (such as tabs or bullet points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ab9821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320996"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "173001cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Updated methodology & Updated Technical Screening Criteria\\n- 1-\\n\\nMarch 2020\\n\\n\\x0cAbout this report\\nThis document includes an updated Part B: Methodology from the June 2019 report and an updated Part\\nF: Full list of technical screening criteria. The other original sections from the June 2019 report can be\\nfound as labelled in the June 2019 report.\\nPART A\\n\\nExplanation of the Taxonomy approach. This section sets out the role and importance of\\nsustainable finance in Europe from a policy and investment perspective, the rationale for\\nthe development of an EU Taxonomy, the daft regulation and the mandate of the TEG.\\n\\nPART B\\n\\nMethodology. This explains the methodologies for developing technical screening\\ncriteria for climate change mitigation objectives, adaptation objectives and ‘do no\\nsignificant harm’ to other environmental objectives in the legislative proposal.\\nThis has been updated since 2019.\\n\\nPART C\\n\\nTaxonomy user and use case analysis. This section provides practical guidance to\\npotentia'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e007ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = re.split(r\"\\s*?\\n\\s*?\\n\\s*?\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17885144",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = 200\n",
    "paragraphs = [para for para in paragraphs if len(para) > min_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2367222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1627"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6b8a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_paragraph(text):\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"  \", \" \").strip(\" \")\n",
    "    return re.sub(r'[^\\w\\s]', '', text).strip(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da95d3",
   "metadata": {},
   "source": [
    "## Store the paragraphs in a DataFrame with the column “paragraph” using the pandas library and save the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "202c2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'paragraph': paragraphs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e078896c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About this report\\nThis document includes an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation of the Taxonomy approach. This sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Methodology. This explains the methodologies f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full list of technical screening criteria. Thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disclaimer\\nThis report represents the overall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  \n",
       "About this report\\nThis document includes an ...\n",
       "1  Explanation of the Taxonomy approach. This sec...\n",
       "2  Methodology. This explains the methodologies f...\n",
       "3  Full list of technical screening criteria. Thi...\n",
       "4  Disclaimer\\nThis report represents the overall..."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "53634d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['paragraph'] = df['paragraph'].apply(clean_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "81f01859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About this report This document includes an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation of the Taxonomy approach This sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Methodology This explains the methodologies fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full list of technical screening criteria This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disclaimer This report represents the overall ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  \n",
       "About this report This document includes an u...\n",
       "1  Explanation of the Taxonomy approach This sect...\n",
       "2  Methodology This explains the methodologies fo...\n",
       "3  Full list of technical screening criteria This...\n",
       "4  Disclaimer This report represents the overall ..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab8d169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606fe50",
   "metadata": {},
   "source": [
    "# M2 Question Paragraph Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40b08ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522e174",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Build a text vectorizer that finds the best matching paragraph for the provided set of questions and qualitatively evaluates the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d93fc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ad18fd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>About this report This document includes an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Explanation of the Taxonomy approach This sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Methodology This explains the methodologies fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Full list of technical screening criteria This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Disclaimer This report represents the overall ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          paragraph\n",
       "0           0  \n",
       "About this report This document includes an u...\n",
       "1           1  Explanation of the Taxonomy approach This sect...\n",
       "2           2  Methodology This explains the methodologies fo...\n",
       "3           3  Full list of technical screening criteria This...\n",
       "4           4  Disclaimer This report represents the overall ..."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45544c",
   "metadata": {},
   "source": [
    "## Initiate a TF-IDF model trained on the paragraphs from the previous milestone by using the TfidfVectorizer class from the scikit-learn library. \n",
    "\n",
    "This model will provide a representation for each paragraph or each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "055088d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c0e470d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_paragraphs = vectorizer.fit_transform(df['paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3e55cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1627, 6496)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_paragraphs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe32f4",
   "metadata": {},
   "source": [
    "## Transform all the paragraphs into representations and calculate a distance in the representation space between each question and all the paragraphs. \n",
    "\n",
    "The distance can be calculated using the linear_kernel function from the scikit-learn library. Sort all the distances and match the paragraph that best corresponds to each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7ad2074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    [\"What fuel is used for manufacturing of chlorine?\"],\n",
    "    [\"What metric is used for evaluating emission?\"],\n",
    "    [\"How can carbon emission of the processes of cement clinker be reduced?\"],\n",
    "    [\"How is the Weighted Cogeneration Threshold calculated?\"],\n",
    "    [\"What is carbon capture and sequestration?\"],\n",
    "    [\"What stages does CCS consist of?\"],\n",
    "    [\"What should be the average energy consumption of a water supply system?\"],\n",
    "    [\"What are examples of sludge treatments?\"],\n",
    "    [\"How is the process of anaerobic digestion?\"],\n",
    "    [\"How is reforestation defined?\"],\n",
    "    [\"What is the threshold of emssion for inland passenger water transport?\"], \n",
    "    [\"What are the requirements of reporting for electricity generation from natural gas where there might be fugative emissions?\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0acc27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Iterate through the questions and transform each of them to their vector representation. \n",
    "# Then use linear_kernel to get the distances and get the smallest one.\n",
    "vector_representations = []\n",
    "\n",
    "for question in questions:\n",
    "    vec_rep = vectorizer.transform(question)\n",
    "    lk_rank = linear_kernel(vec_rep, vectorized_paragraphs).flatten()\n",
    "    vector_representations.append((question, df[\"paragraph\"][lk_rank.argsort()[-1]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea133dc3",
   "metadata": {},
   "source": [
    "## Bonus: Train a Doc2vec model with the paragraphs using the Doc2vec model provided by the gensim library. \n",
    "\n",
    "Similar to the TF-IDF model, Doc2vec provides a representation for the paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2c6695d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def read_corpus(text, tokens_only=False):\n",
    "    for i, line in enumerate(text):\n",
    "        tokens = gensim.utils.simple_preprocess(line)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "corpus = list(read_corpus(df[\"paragraph\"].values))\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(corpus)\n",
    "model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53698f",
   "metadata": {},
   "source": [
    "## Bonus: Given the representation of the paragraphs, use the most_similar method in the gensim library, which uses cosine distance to get the paragraphs that best match the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a956af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_similarities = []\n",
    "for question in questions:\n",
    "    q1 = list(read_corpus(question, tokens_only=True))\n",
    "    inferred_vector = model.infer_vector(q1[0])\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    doc2vec_similarities.append((question, df[\"paragraph\"][sims[0][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8657a1",
   "metadata": {},
   "source": [
    "## Bonus: Evaluate the two different methods for matching questions to paragraphs and pick the better performing one to use in the next milestone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "80d9e5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What fuel is used for manufacturing of chlorine?\n",
      "tfidf: Rationale The manufacturing process of carbon black accounts for approximately 34 of the GHG emissions from the chemical sector while the manufacturing of soda ash accounts for 15 of the emissions 212 The manufacturing process of chlorine is extremely energyintensive with chloralkali process accounting for 17 of total electrical consumption of the European chemical and petrochemical industry213 Reducing the manufacturing emissions for carbon black and soda ash and improving energy efficiency in the manufacturing of chlorine can positively contribute to the mitigation objective Moreover it is recognised that soda ash used in double glazing can enhance building efficiency gains The absolute performance approach has been proposed in order to identify the maximum acceptable carbon intensities of the manufacturing processes of carbon black and soda ash that the activities should comply with in order to be able to substantially contribute to the mitigation objective For the manufacturing of chlorine a process that uses electricity to fuel the electrolysis process the absolute performance approach has been proposed in order to identify the energy intensity threshold In addition to complying with the energy efficiency threshold the process shall be based on low carbon electricity ETS product benchmarks have been selected as thresholds for the manufacturing of carbon black and soda ash They reflect the average performance of the 10 most efficient installations in a sector Emissions covered  Scope 1 All direct emissions related to the production the process direct emissions and the emissions due to fuel use for energy production  Note on the electricity According to the methodology to calculate ETS benchmarks emissions from electricity are considered where direct emissions and indirect emissions from electricity are to a certain level interchangeable as is the case for carbon black but not for soda ash214 For chlorine the value corresponding to an efficient level of electricity consumption was selected as the threshold given that the main source of energy used for the production of chlorine is electricity and by improving the energy efficiency of the process as well as using low carbon electricity sources the activity can substantially contribute to the climate change mitigation objective httpseurlexeuropaeuLexUriServLexUriServdouriOJC201238700050013ENPDF httpsepubwupperinstorgfrontdoordeliverindexdocId6478file6478_Lechtenboehmerpdf\n",
      "\n",
      "doc2vec: The manufacturing of organic chemicals is associated with significant CO2 emissions Minimizing process emissions and promoting the manufacturing of organic chemicals with renewable feedstock can contribute to the mitigation objective Mitigation measures are eligible provided they are incorporated into a single investment plan within a determined time frame 5 or 10 years that outlines how each of the measures in combination with others will in combination enable the activity to meet the threshold defined below actions\n",
      "--------------------\n",
      "What metric is used for evaluating emission?\n",
      "tfidf: \f",
      "transport sector The Heavy Duty CO2 Regulation uses a g CO2km metric To convert this to a g CO2tonnekm metric the average payload for the road freight vehicles should be applied Once reference value data is available it is expected that the taxonomy will specify CO2etkm threshold values\n",
      "\n",
      "doc2vec: \f",
      "Furthermore the platform should take into consideration the value chain and circular economy aspects of chemicalsproductsbyproducts For example Chlorine and PVC are required for the production of PVC doors and windows which are necessary for improved energy efficiency of the building sector Such value chain and CE considerations would follow a similar logic applied to sodaash in the current version of the Taxonomy on the basis that it is required for glazing of double and triple glazed windows 3 The platform is recommended to regularly update the thresholds paying particular attention to\n",
      "--------------------\n",
      "How can carbon emission of the processes of cement clinker be reduced?\n",
      "tfidf: Thresholds for cement Clinker A are applicable to plants that produce clinker only and do not produce finished cement All other plants need to meet the thresholds for cement or alternative binder A Cement clinker Specific emissions calculated according to the methodology used for EUETS benchmarks associated to the clinker production processes are lower than the value of the related EUETS benchmark As of February 2020 the EUETS benchmark value for cement clinker manufacturing is 0766 tCO2et of clinker198 B Cement Specific emissions associated to the clinker and cement production processes are lower than 0498 tCO2et of cement or alternative binder 199\n",
      "\n",
      "doc2vec: Calculations of carbon stocks and GHG emissions levels should include the following though it is recognised that in practice the scope of GHG counted will be subject to the technical capabilities of the GHG accounting tools being used o\n",
      "--------------------\n",
      "How is the Weighted Cogeneration Threshold calculated?\n",
      "tfidf: Cogeneration of Heat and Power is covered under Construction and operation of a facility used for cogeneration of heatcooling and Power threshold Generation of heatcool is covered under the Generation of heatcool threshold\n",
      "\n",
      "doc2vec: The economic activity reduces or facilitates adaptation to physical climate risks beyond the boundaries of the activity itself The activity will need to demonstrate how it supports adaptation of others through\n",
      "--------------------\n",
      "What is carbon capture and sequestration?\n",
      "tfidf: Users of the Taxonomy should identify and explain which criteria they are responding to Do no significant harm assessment The main environmental impacts associated with Capture of Anthropogenic Emissions are due to chemicalstechnologies used to capture carbon 1 Mitigation\n",
      "\n",
      "doc2vec: \f",
      "The DNSH criteria below should be considered in combination with the SFM requirements of the forest mitigation Taxonomy criterion 1 The criteria can be informed by applying forest certification using independent thirdparty schemes that are regularly audited Compliance shall be reported through a forest management plan or equivalent as per criterion 3 of the forest mitigation Taxonomy 2 Adaptation\n",
      "--------------------\n",
      "What stages does CCS consist of?\n",
      "tfidf: \f",
      "low carbon economy and with the inbuilt flexibility on options for demonstrating compliance they can be applied globally Impact of these proposals The activities do not impose major additional implementation costs on the stakeholders because as explained for most of them  except water collection treatment and supply  the climate mitigation effects are an inherent result of key characteristics of the correspondent business models and thus should come along without significant further cost Considering water collection treatment and supply additional investments may be necessary in order to reach certain thresholds however the corresponding costs may partially be equalized by cost savings from higher energy efficiency There should be no systematic distortive effect of the activities on the number and competitive position of the companies in the corresponding sectors The overall sectoral technological impact will depend on the state of the water wastewater and waste management in each Member State in terms of eg regional coverage of different management technologies Outside of the EU the technological impact could be even greater if the state of the sector in an individual country or region is below that of the EU Clear additional beneficial environmental effects can be assumed for eg water circular economy and pollution Employment effects should be positive and further beneficial economic impacts are induced through increased investments and the demand for consumer goods Why carbon capture and sequestration CCS is included in the Taxonomy Carbon capture and sequestration CCS is a key technology for the decarbonisation of Europe It is included in all pathways presented by the European Commission in its LongTerm Strategic Vision document and is relied upon heavily in threeoutoffour scenarios outlined by the IPCC in the Special Report on 15 Degrees A typical CCS chain consists of three main stages capture transport and storage CO 2 transport and storage are established and proven processes with decades of operation and wellestablished regulation here in Europe The Technical Expert Group has developed criteria to define the eligibility of facilities used to capture carbon dioxide directly from the atmosphere and separately to capture carbon dioxide directly from anthropogenic activities CCS can be eligible in any sectoractivity if it enables that primary activity to operate in compliance with the threshold  for example steel cement or electricity production\n",
      "\n",
      "doc2vec: Users of the Taxonomy should identify and explain which criteria they are responding to Do no significant harm assessment The main potential significant harm to other environmental objectives from Production of electric energy from highenthalpy geothermal system is associated with\n",
      "--------------------\n",
      "What should be the average energy consumption of a water supply system?\n",
      "tfidf: \f",
      "The unit of measurement is the Infrastructure Leakage Index ILI 296 the target value of low leakage is an ILI of 15 Rationale The water supply sector is a wide and varied sector with very different performance conditions depending on the water source the necessary treatment the topography of the supplied area the length of the network etc ILI and kwhm3 supplied are chosen as parameters in order to measure the efficiency of a water supply system An average energy consumption of a water supply system of 05 kwh per cubic meter billedunbilled authorized water supply indicates a high performing system in terms of energy consumption Several energy efficiency measures can reduce directly the energy consumption in a water supply system enabling significant reductions of GHG emissions these are inter alia\n",
      "\n",
      "doc2vec: Adjustments to thresholds energy thresholds should be revisited on a fiveyear basis in order to reflect state of the art research and progress on decarbonisation efforts Particularly the emission threshold for electricity generation should be reduced every five years\n",
      "--------------------\n",
      "What are examples of sludge treatments?\n",
      "tfidf: No threshold applies Rationale Sewage sludge is a byproduct of wastewater treatment with organic and inorganic content The organic content of the sludge is subject of decomposition which might occur under controlled circumstances in sludge treatment installations or under uncontrolled circumstances in the final disposal with significant GHG emissions mainly methane Anaerobic Digestion AD and in some cases aerobic digestion are examples of sludge treatments In AD microorganisms decompose the organic matter of the sludge in the absence of oxygen and produce methanerich biogas The primary climate mitigation effect of biogas is its use a source of renewable energy in multiple forms and applications displacing fossil fuels 297 As an additional contribution to climate mitigation the sludge can be turned into a recyclable product eg as fertilizer substituting synthetic fertilizers\n",
      "\n",
      "doc2vec: Network connectivity infrastructure to channel water and wastewater flows between plants NACE 422 Construction of utility projects Distributed smallscale closedloop systems NACE 422 Construction of utility projects\n",
      "--------------------\n",
      "How is the process of anaerobic digestion?\n",
      "tfidf: For Anaerobic Digestion of Biowaste and Sewage Sludge refer to activities 55 and 53 respectively Any other anaerobic digestion of organic material not covered under sections 53 and 55 is eligible provided that  methane leakage from relevant facilities eg for biogas production and storage energy generation digestate storage is controlled by a monitoring plan\n",
      "\n",
      "doc2vec: The economic activity reduces or facilitates adaptation to physical climate risks beyond the boundaries of the activity itself The activity will need to demonstrate how it supports adaptation of others through\n",
      "--------------------\n",
      "How is reforestation defined?\n",
      "tfidf: Reforestation Reforestation is defined as the reestablishment of forest through planting andor deliberate seeding on land classified as forest It implies no change of land use includes plantingseeding of temporarily unstocked forest areas as well as plantingseeding of areas with forest cover It includes coppice from trees that were originally planted or seeded69 The FAO FRA definition of reforestation excludes natural regeneration However the Taxonomy recognises the importance of natural regeneration to the increased carbon sink and stock potential provided by forests in general It is therefore included explicitly within this context in line with the FAO FRA definition of naturally regenerating forest70 In the context of the Taxonomy the category reforestation applies in cases following extreme events wind throws fires etc and not as part of normal legally binding obligation to reforest after harvesting\n",
      "\n",
      "doc2vec: Criterion 1 Mandatory application of the following Sustainable Forest Management SFM requirements o Identify and apply forest management practices that increase existing carbon stocks  considering the nonexhaustive list of examples practices in the Annex F2 however allowing for\n",
      "--------------------\n",
      "What is the threshold of emssion for inland passenger water transport?\n",
      "tfidf: Users of the Taxonomy should identify and explain which criteria they are responding to Do no significant harm assessment The main potential significant harm to other environmental objectives from the operation of inland passenger and freight water transport are summarised as follows\n",
      "\n",
      "doc2vec: This criterion is subject to regular review Rationale Emissions captured from Direct Air Capture cannot be attributed towards meeting the threshold of another economic activity in the Taxonomy The TEG recommends that the following ISO standards are incorporated into this Taxonomy threshold when made publicly available\n",
      "--------------------\n",
      "What are the requirements of reporting for electricity generation from natural gas where there might be fugative emissions?\n",
      "tfidf: Scope 1 all direct emissions related to the production the processs direct emissions and the emissions due to fuel use for onsite energy production Scope 2 Electricity consumption for electrolysis process and related emissions from the generation of the electricity used\n",
      "\n",
      "doc2vec: Precision and multiphase feeding techniques where the nutrient requirements of groups of animals or individual animals are targeted in feed formulation This can reduce nitrogen excretion and subsequent N2O emissions from manure and also increase feed efficiency in general reducing the feed related upstream emissions\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for ic,(question, context)  in enumerate(vector_representations):\n",
    "    print(question[0])\n",
    "    print(f\"tfidf: {context}\\n\\ndoc2vec: {doc2vec_similarities[ic][1]}\")\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d8f11",
   "metadata": {},
   "source": [
    "# 3. Set-up Transformers for Question-Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884553d9",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Get familiar with using the Hugging Face library for applied purposes\n",
    "The main goal is to extract the answer given a question-paragr## aph tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3891cb",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Either of the cases will require pointing to an existing pretrained or, in our case, fine-tuned model. You can find a library of pretrained and fine-tuned models at Hugging Face Models. Notice that some of the models are quite large and perhaps will either not work or slow your computer down. A smaller model that could be a good starting point is distilbert-base-uncased-distilled-squad.\n",
    "\n",
    "- There are other libraries you could use to develop a Question-Answering model. However, for this project we want to focus on the Hugging Face transformers since they are already pretrained and fine tuned. They also provide a very simple interface to set up and use the model.\n",
    "\n",
    "- There are two different methods to use the transformers library. There are pros and cons for both, but for the purposes of this project it does not make any difference which one you choose.\n",
    "\n",
    "- We will only use exact matches as an evaluation metric, as mentioned above. This is basically a count of the number of data points that the model predicts correctly over the total number of data points. A regular string match should be sufficient for the purpose of this project. Again, you do not need to use the entire dataset since it can take a lot of computational power, but rather sample some data from it (perhaps 1000 data points or so).m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a8ccf6",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- Real-World Natural Language Processing by Masato Hagiwara Chapter 9, section 3, “Case study 1: Sentiment analysis with BERT,” provides an example of using the Hugging Face transformers library.\n",
    "\n",
    "\n",
    "- Taming Text by Grant S. Ingersoll, Thomas S. Morton, and Andrew L. Farris Chapter 8, “Building an example question answering system,” is helpful if you want to understand the theory behind building a question answering system.\n",
    "\n",
    "\n",
    "- Natural Language Processing in Action by Hobson Lane, Cole Howard, and Hannes Hapke Chapter 10, “Sequence-to-sequence models and attention,” contains theoretical background on how transformers work.\n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- HuggingFace Transformers library documentation will be used for the question answering.\n",
    "\n",
    "- Question answering tutorial https://huggingface.co/transformers/usage.html#extractive-question-answering – Note that we will use PyTorch for this project.\n",
    "\n",
    "- Information about the Stanford question-answer dataset https://rajpurkar.github.io/SQuAD-explorer/, as well as a list of how different algorithms perform on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c53e8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"distilbert-base-uncased-distilled-squad\"\n",
    "TEST_SAMPLE_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aea08d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "with open(\"data/dev-v2.0.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def get_question_answers_context(data):\n",
    "    # this function should provide tuples of question, answer and context from the data\n",
    "    tuples = []\n",
    "    for i in range(len(data['data'])):\n",
    "        for j in range(len(data['data'][i]['paragraphs'])):\n",
    "            tuples.extend(data['data'][i]['paragraphs'][j]['qas'])\n",
    "    return tuples\n",
    "\n",
    "qac = random.sample(get_question_answers_context(data), TEST_SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45cbe93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c3dc56a",
   "metadata": {},
   "source": [
    "## Import the pipeline class.\n",
    "\n",
    "This will be more straightforward and you will get less exposure to the components of the transformer than in the previous milestone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "256503f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3cd621",
   "metadata": {},
   "source": [
    "## Set up the model and point to an existing pretrained and fine-tuned model. \n",
    "\n",
    "(See the notes for more detail.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f52acd",
   "metadata": {},
   "source": [
    "## Use the SQuAD dev dataset to test how the different models are performing. \n",
    "\n",
    "The metric you will need to set up here is an exact match metric, which means you just need to see whether the predicted text is exactly the same as the answer provided in the dataset. You do not need to use the entire dataset, but make sure to evaluate a sample to ensure that the model performs well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e943cd",
   "metadata": {},
   "source": [
    "## Explore a few different models and evaluate which performs the best. \n",
    "\n",
    "For this project, we will only use exact matches as an evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbcc38",
   "metadata": {},
   "source": [
    "## Bonus: Use the question and paragraph pairs from the previous milestone as input to allow the model to predict the location of the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247ebcd",
   "metadata": {},
   "source": [
    "## Bonus: If you want to get a better understanding of setting up the model, you can import the AutoTokenizer and AutoModelForQuestionAnswering classes from the transformers library.\n",
    "\n",
    "### Here you will get more insight into the structure of the pipeline—the two classes are the two main parts of the transformers architecture.\n",
    "\n",
    "### One is the tokenization model which tokenizes both the question and the context (paragraph), and the second is the Question-Answering model which predicts where in the sequenced tokens of the context the answer starts and ends, given the question tokens as inputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
