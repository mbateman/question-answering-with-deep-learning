{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4ae722",
   "metadata": {},
   "source": [
    "# M1 Extracting Paragraphs from the EU Taxonomy Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bafd6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import textract\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9afb7",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Process the EU sustainable finance taxonomy PDF file and extract and clean all the paragraphs in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc6126",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- The most important part of this milestone is to be able to segment the document into many paragraphs. The data cleaning is secondary.\n",
    "\n",
    "\n",
    "- There might be a need to change the cleaning method as we progress in the project.\n",
    "\n",
    "\n",
    "- Note that there are methods you can use that will segment the document better and extract all of the parts in a clean manner. However, for the purposes of this project, we can just extract all the paragraphs in a somewhat rough matter. The segmentation and extraction have great importance in the overall result of any NLP processing solution you want to run on the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c3e113",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "- Chapter 2, Regular Expressions, Text Normalization, Edit Distance, in Speech and Language Processing by Daniel Jurafsky and James H. Martin covers all the basics of understanding regular expressions, up to an intermediate level.\n",
    "\n",
    "- A few specific examples from the Python package can be used as a simple tutorial to extract text from PDF files. The example here is similar to what we will need for this project.\n",
    "\n",
    "- “Regular Expressions — An excellent tool for text analysis or NLP” by Niwratti Kasture is a very good overview of regular expressions.\n",
    "\n",
    "- [NLP] Basics: Understanding Regular Expressions by Céline Van den Rul is another good overview of regular expressions.\n",
    "regular expressions 101 is a great resource to test out regular expressions.\n",
    "\n",
    "- re — Regular expression operations is documentation on the package used in this milestone.\n",
    "\n",
    "- Read the textract documentation to see how to extract the text from the PDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f2285",
   "metadata": {},
   "source": [
    "## Help\n",
    "\n",
    "- In this case, this is the function you want to use to process and extract the text from the PDF file:\n",
    "\n",
    "\n",
    "text = textract.process(\"path/to/file.pdf\")\n",
    "\n",
    "- For regular expressions, you want to take advantage of the spacing and newline characters to split the paragraphs. To do this, you will need to set up a pattern that includes \\s. The library re has the function split(), which you should use to split the text by a given specific pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f7ca7",
   "metadata": {},
   "source": [
    "## Download the EU sustainable finance taxonomy PDF from Taxonomy Report: Technical Annex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbab343",
   "metadata": {},
   "source": [
    "## Load the EU sustainable finance taxonomy PDF file using the textract library and decode it. \n",
    "\n",
    "Look through the text to ensure that you have got all the text and that the decoding did not produce any bad characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52dfc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = textract.process('EUtaxonomy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c5902a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "167913a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = textract.process('EUtaxonomy.pdf', method='pdfminer').decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d1a94",
   "metadata": {},
   "source": [
    "## Use regular expressions to split the paragraphs and clean the text. \n",
    "\n",
    "The loaded text will be in raw format and will need to be segmented into paragraphs. These paragraphs will also need to be cleaned by removing newline characters and other characters that do not bring any semantic value to the paragraph (such as tabs or bullet points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ab9821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320996"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "173001cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Updated methodology & Updated Technical Screening Criteria\\n- 1-\\n\\nMarch 2020\\n\\n\\x0cAbout this report\\nThis document includes an updated Part B: Methodology from the June 2019 report and an updated Part\\nF: Full list of technical screening criteria. The other original sections from the June 2019 report can be\\nfound as labelled in the June 2019 report.\\nPART A\\n\\nExplanation of the Taxonomy approach. This section sets out the role and importance of\\nsustainable finance in Europe from a policy and investment perspective, the rationale for\\nthe development of an EU Taxonomy, the daft regulation and the mandate of the TEG.\\n\\nPART B\\n\\nMethodology. This explains the methodologies for developing technical screening\\ncriteria for climate change mitigation objectives, adaptation objectives and ‘do no\\nsignificant harm’ to other environmental objectives in the legislative proposal.\\nThis has been updated since 2019.\\n\\nPART C\\n\\nTaxonomy user and use case analysis. This section provides practical guidance to\\npotentia'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e007ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = re.split(r\"\\s*?\\n\\s*?\\n\\s*?\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8afdedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = 200\n",
    "paragraphs = [para for para in paragraphs if len(para) > min_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2367222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1627"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6b8a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_paragraph(text):\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"  \", \" \").strip(\" \")\n",
    "    return re.sub(r'[^\\w\\s]', '', text).strip(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da95d3",
   "metadata": {},
   "source": [
    "## Store the paragraphs in a DataFrame with the column “paragraph” using the pandas library and save the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "202c2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'paragraph': paragraphs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e078896c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About this report\\nThis document includes an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation of the Taxonomy approach. This sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Methodology. This explains the methodologies f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full list of technical screening criteria. Thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disclaimer\\nThis report represents the overall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  \n",
       "About this report\\nThis document includes an ...\n",
       "1  Explanation of the Taxonomy approach. This sec...\n",
       "2  Methodology. This explains the methodologies f...\n",
       "3  Full list of technical screening criteria. Thi...\n",
       "4  Disclaimer\\nThis report represents the overall..."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "53634d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['paragraph'] = df['paragraph'].apply(clean_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "81f01859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About this report This document includes an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation of the Taxonomy approach This sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Methodology This explains the methodologies fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full list of technical screening criteria This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disclaimer This report represents the overall ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  \n",
       "About this report This document includes an u...\n",
       "1  Explanation of the Taxonomy approach This sect...\n",
       "2  Methodology This explains the methodologies fo...\n",
       "3  Full list of technical screening criteria This...\n",
       "4  Disclaimer This report represents the overall ..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab8d169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606fe50",
   "metadata": {},
   "source": [
    "# M2 Question Paragraph Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40b08ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522e174",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Build a text vectorizer that finds the best matching paragraph for the provided set of questions and qualitatively evaluates the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e276a",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- This is the first information retrieval step. For this step we will use a traditional method for searching documents.\n",
    "\n",
    "\n",
    "- TF-IDF is, despite being an older method, usually preferred since it performs quite well and is usually faster than other representation methods.\n",
    "\n",
    "\n",
    "- Doc2vec can provide better representations if trained on a larger corpus such as Wikipedia. For the purpose of the project, TF-IDF might perform better if Doc2vec is only trained on the EU taxonomy document.\n",
    "\n",
    "\n",
    "The list of questions for this project are the following:\n",
    "\n",
    "\n",
    "- What fuel is used for the manufacturing of chlorine?\n",
    "\n",
    "\n",
    "- What metric is used for evaluating emission?\n",
    "\n",
    "\n",
    "- How can carbon emission of the processes of cement clinker be reduced?\n",
    "\n",
    "\n",
    "- How is the Weighted Cogeneration Threshold calculated?\n",
    "\n",
    "\n",
    "- What are carbon capture and sequestration?\n",
    "\n",
    "\n",
    "- What stages does CCS consist of?\n",
    "\n",
    "\n",
    "- What should be the average energy consumption of a water supply system?\n",
    "\n",
    "\n",
    "- What are sludge treatments? -What is the process of anaerobic digestion?\n",
    "\n",
    "\n",
    "- How is reforestation defined?\n",
    "\n",
    "\n",
    "- What is the threshold of emission for inland passenger water transport?\n",
    "\n",
    "\n",
    "- What are the requirements of reporting for electricity generation from natural gas where there might be fugitive emissions?-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630a783",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- Natural Language Processing in Action by Hobson Lane, Cole Howard, and Hannes Hapke\n",
    "  Chapter 3, “Math with words (TF-IDF vectors),” explains TF-IDF vectors. The first 3 sections are relevant. \n",
    "  If you want to understand TF-IDF, section 4, “Topic modeling,” and subsequent sections are more practical and relevant.\n",
    "\n",
    "\n",
    "- Real-World Natural Language Processing by Masato Hagiwara\n",
    "    Chapter 3, “Word and Document Embeddings,” discusses word and document embeddings, the theory behind Doc2Vec. \n",
    "    This chapter will allow you to understand the general theory behind text vectorization.\n",
    "\n",
    "\n",
    "- Deep Learning for Natural Language Processing by Stephan Raaijmakers\n",
    "    Chapter 3, “Text Embeddings,” includes more on document embeddings, for those who want to get a deeper insight in the theory.\n",
    "\n",
    "\n",
    "## Additional resources\n",
    "\n",
    "- Gensim library documentation, which should be used to get Doc2vec embeddings https://radimrehurek.com/gensim/\n",
    "\n",
    "\n",
    "- An example of how to find the most similar paragraph and sentence   https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py\n",
    "\n",
    "\n",
    "- TF-IDF library documentation https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "- Documentation on the vector distance measure library \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.linear_kernel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62bb2d6",
   "metadata": {},
   "source": [
    "## Help\n",
    "\n",
    "- To build a vectorizer, use the scikit-learn module TfidfVectorizer, which you will need to fit to the corpus.\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(corpus)\n",
    "\n",
    "- The second step is to use linear_kernel() to get the distance matrix for the different vectors and then sort them to get the pairs that are closest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d93fc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "99b5f52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>About this report This document includes an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Explanation of the Taxonomy approach This sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Methodology This explains the methodologies fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Full list of technical screening criteria This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Disclaimer This report represents the overall ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          paragraph\n",
       "0           0  \n",
       "About this report This document includes an u...\n",
       "1           1  Explanation of the Taxonomy approach This sect...\n",
       "2           2  Methodology This explains the methodologies fo...\n",
       "3           3  Full list of technical screening criteria This...\n",
       "4           4  Disclaimer This report represents the overall ..."
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45544c",
   "metadata": {},
   "source": [
    "## Initiate a TF-IDF model trained on the paragraphs from the previous milestone by using the TfidfVectorizer class from the scikit-learn library. \n",
    "\n",
    "This model will provide a representation for each paragraph or each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "055088d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c0e470d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_paragraphs = vectorizer.fit_transform(df['paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d3e55cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1627, 6496)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_paragraphs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe32f4",
   "metadata": {},
   "source": [
    "## Transform all the paragraphs into representations and calculate a distance in the representation space between each question and all the paragraphs. \n",
    "\n",
    "The distance can be calculated using the linear_kernel function from the scikit-learn library. Sort all the distances and match the paragraph that best corresponds to each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7ad2074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    [\"What fuel is used for manufacturing of chlorine?\"],\n",
    "    [\"What metric is used for evaluating emission?\"],\n",
    "    [\"How can carbon emission of the processes of cement clinker be reduced?\"],\n",
    "    [\"How is the Weighted Cogeneration Threshold calculated?\"],\n",
    "    [\"What is carbon capture and sequestration?\"],\n",
    "    [\"What stages does CCS consist of?\"],\n",
    "    [\"What should be the average energy consumption of a water supply system?\"],\n",
    "    [\"What are examples of sludge treatments?\"],\n",
    "    [\"How is the process of anaerobic digestion?\"],\n",
    "    [\"How is reforestation defined?\"],\n",
    "    [\"What is the threshold of emssion for inland passenger water transport?\"], \n",
    "    [\"What are the requirements of reporting for electricity generation from natural gas where there might be fugative emissions?\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0acc27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Iterate through the questions and transform each of them to their vector representation. \n",
    "# Then use linear_kernel to get the distances and get the smallest one.\n",
    "vector_representations = []\n",
    "\n",
    "for question in questions:\n",
    "    vec_rep = vectorizer.transform(question)\n",
    "    lk_rank = linear_kernel(vec_rep, vectorized_paragraphs).flatten()\n",
    "    vector_representations.append((question, df[\"paragraph\"][lk_rank.argsort()[-1]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea133dc3",
   "metadata": {},
   "source": [
    "## Bonus: Train a Doc2vec model with the paragraphs using the Doc2vec model provided by the gensim library. \n",
    "\n",
    "Similar to the TF-IDF model, Doc2vec provides a representation for the paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "91fa7976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def read_corpus(text, tokens_only=False):\n",
    "    for i, line in enumerate(text):\n",
    "        tokens = gensim.utils.simple_preprocess(line)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "corpus = list(read_corpus(df[\"paragraph\"].values))\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(corpus)\n",
    "model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53698f",
   "metadata": {},
   "source": [
    "## Bonus: Given the representation of the paragraphs, use the most_similar method in the gensim library, which uses cosine distance to get the paragraphs that best match the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2791c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_similarities = []\n",
    "for question in questions:\n",
    "    q1 = list(read_corpus(question, tokens_only=True))\n",
    "    inferred_vector = model.infer_vector(q1[0])\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    doc2vec_similarities.append((question, df[\"paragraph\"][sims[0][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8657a1",
   "metadata": {},
   "source": [
    "## Bonus: Evaluate the two different methods for matching questions to paragraphs and pick the better performing one to use in the next milestone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "80d9e5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What fuel is used for manufacturing of chlorine?\n",
      "tfidf: Rationale The manufacturing process of carbon black accounts for approximately 34 of the GHG emissions from the chemical sector while the manufacturing of soda ash accounts for 15 of the emissions 212 The manufacturing process of chlorine is extremely energyintensive with chloralkali process accounting for 17 of total electrical consumption of the European chemical and petrochemical industry213 Reducing the manufacturing emissions for carbon black and soda ash and improving energy efficiency in the manufacturing of chlorine can positively contribute to the mitigation objective Moreover it is recognised that soda ash used in double glazing can enhance building efficiency gains The absolute performance approach has been proposed in order to identify the maximum acceptable carbon intensities of the manufacturing processes of carbon black and soda ash that the activities should comply with in order to be able to substantially contribute to the mitigation objective For the manufacturing of chlorine a process that uses electricity to fuel the electrolysis process the absolute performance approach has been proposed in order to identify the energy intensity threshold In addition to complying with the energy efficiency threshold the process shall be based on low carbon electricity ETS product benchmarks have been selected as thresholds for the manufacturing of carbon black and soda ash They reflect the average performance of the 10 most efficient installations in a sector Emissions covered  Scope 1 All direct emissions related to the production the process direct emissions and the emissions due to fuel use for energy production  Note on the electricity According to the methodology to calculate ETS benchmarks emissions from electricity are considered where direct emissions and indirect emissions from electricity are to a certain level interchangeable as is the case for carbon black but not for soda ash214 For chlorine the value corresponding to an efficient level of electricity consumption was selected as the threshold given that the main source of energy used for the production of chlorine is electricity and by improving the energy efficiency of the process as well as using low carbon electricity sources the activity can substantially contribute to the climate change mitigation objective httpseurlexeuropaeuLexUriServLexUriServdouriOJC201238700050013ENPDF httpsepubwupperinstorgfrontdoordeliverindexdocId6478file6478_Lechtenboehmerpdf\n",
      "\n",
      "doc2vec: The manufacturing of hydrogen is a highly carbonintensive activity within the chemical industry206Reducing the emissions from the manufacturing activity itself can positively contribute to the mitigation objectives Hydrogen generated as a process by product of the chloralkali production is not eligible Mitigation measures are eligible provided they are incorporated into a single investment plan within a determined time frame 5 or 10 years that outlines how each of the measures in combination with others will in combination enable the activity to meet the threshold defined below actions\n",
      "--------------------\n",
      "What metric is used for evaluating emission?\n",
      "tfidf: \f",
      "transport sector The Heavy Duty CO2 Regulation uses a g CO2km metric To convert this to a g CO2tonnekm metric the average payload for the road freight vehicles should be applied Once reference value data is available it is expected that the taxonomy will specify CO2etkm threshold values\n",
      "\n",
      "doc2vec: In addition it is required that a low emission Napplication technology is used eg slurry injection incorporating manure in the soil within 2 hours of spreading and fertilizer spreaders which have low coefficient of variation synthetic fertilizer and\n",
      "--------------------\n",
      "How can carbon emission of the processes of cement clinker be reduced?\n",
      "tfidf: Thresholds for cement Clinker A are applicable to plants that produce clinker only and do not produce finished cement All other plants need to meet the thresholds for cement or alternative binder A Cement clinker Specific emissions calculated according to the methodology used for EUETS benchmarks associated to the clinker production processes are lower than the value of the related EUETS benchmark As of February 2020 the EUETS benchmark value for cement clinker manufacturing is 0766 tCO2et of clinker198 B Cement Specific emissions associated to the clinker and cement production processes are lower than 0498 tCO2et of cement or alternative binder 199\n",
      "\n",
      "doc2vec: Continued compliance with the Sustainable Forest Management SFM requirements is demonstrated and disclosed at 10year intervals through a forest management plan or equivalent that shall be reviewed by an independent thirdparty certifier andor competent authorities as described in Criteria 3 Verified GHG balance baseline43 is calculated for aboveground carbon pools based on growthyield curves for species per m3yearha carbon convertible Calculating the GHG balance baseline requires knowledge of the area the species and number of trees in case of afforestation and reforestation Using the growthyield curves information will be given on the annual increment in m3yearha which can be used for the basis of the GHG balance The methodology is consistent with the approach in the Revised 1996 IPCC Guidelines for National Greenhouse Gas Inventories IPCC Guidelines it recommends recalculation of the amount of carbon sequestered 1 ton of biomass representing approximately 05 ton of carbon Further one ton of carbon equals 4412  367 tons of carbon dioxide Above ground Carbon stocks shall increase above carbon baseline over a period of 20 years44 Changes in carbon stocks should be disclosed based on growth yield curves in 10 year intervals through a forest management plan or equivalent instrument45 that shall be reviewed by an independent thirdparty certifier andor competent authorities as described in Criteria 346\n",
      "--------------------\n",
      "How is the Weighted Cogeneration Threshold calculated?\n",
      "tfidf: Cogeneration of Heat and Power is covered under Construction and operation of a facility used for cogeneration of heatcooling and Power threshold Generation of heatcool is covered under the Generation of heatcool threshold\n",
      "\n",
      "doc2vec: Manufacturing of iron and steel at the level of performance achieved by best performing plants is considered to make a substantial contribution to climate change mitigation Furthermore secondary production of steel ie using scrap steel is considered eligible due to significantly lower emissions than primary steel production Mitigation measures are eligible provided they are incorporated into a single investment plan within a determined time frame 5 or 10 years that outlines how each of the measures in combination with others will in combination enable the activity to meet the threshold defined below actions\n",
      "--------------------\n",
      "What is carbon capture and sequestration?\n",
      "tfidf: Users of the Taxonomy should identify and explain which criteria they are responding to Do no significant harm assessment The main environmental impacts associated with Capture of Anthropogenic Emissions are due to chemicalstechnologies used to capture carbon 1 Mitigation\n",
      "\n",
      "doc2vec: Identify and manage risks related to water quality andor water consumption at the appropriate level Ensure that water useconservation management plans developed in consultation with relevant stakeholders have been developed and implemented 448\n",
      "--------------------\n",
      "What stages does CCS consist of?\n",
      "tfidf: \f",
      "low carbon economy and with the inbuilt flexibility on options for demonstrating compliance they can be applied globally Impact of these proposals The activities do not impose major additional implementation costs on the stakeholders because as explained for most of them  except water collection treatment and supply  the climate mitigation effects are an inherent result of key characteristics of the correspondent business models and thus should come along without significant further cost Considering water collection treatment and supply additional investments may be necessary in order to reach certain thresholds however the corresponding costs may partially be equalized by cost savings from higher energy efficiency There should be no systematic distortive effect of the activities on the number and competitive position of the companies in the corresponding sectors The overall sectoral technological impact will depend on the state of the water wastewater and waste management in each Member State in terms of eg regional coverage of different management technologies Outside of the EU the technological impact could be even greater if the state of the sector in an individual country or region is below that of the EU Clear additional beneficial environmental effects can be assumed for eg water circular economy and pollution Employment effects should be positive and further beneficial economic impacts are induced through increased investments and the demand for consumer goods Why carbon capture and sequestration CCS is included in the Taxonomy Carbon capture and sequestration CCS is a key technology for the decarbonisation of Europe It is included in all pathways presented by the European Commission in its LongTerm Strategic Vision document and is relied upon heavily in threeoutoffour scenarios outlined by the IPCC in the Special Report on 15 Degrees A typical CCS chain consists of three main stages capture transport and storage CO 2 transport and storage are established and proven processes with decades of operation and wellestablished regulation here in Europe The Technical Expert Group has developed criteria to define the eligibility of facilities used to capture carbon dioxide directly from the atmosphere and separately to capture carbon dioxide directly from anthropogenic activities CCS can be eligible in any sectoractivity if it enables that primary activity to operate in compliance with the threshold  for example steel cement or electricity production\n",
      "\n",
      "doc2vec: Users of the Taxonomy should identify and explain which criteria they are responding to Do no significant harm assessment The main potential significant harm linked to this activity is related to\n",
      "--------------------\n",
      "What should be the average energy consumption of a water supply system?\n",
      "tfidf: \f",
      "The unit of measurement is the Infrastructure Leakage Index ILI 296 the target value of low leakage is an ILI of 15 Rationale The water supply sector is a wide and varied sector with very different performance conditions depending on the water source the necessary treatment the topography of the supplied area the length of the network etc ILI and kwhm3 supplied are chosen as parameters in order to measure the efficiency of a water supply system An average energy consumption of a water supply system of 05 kwh per cubic meter billedunbilled authorized water supply indicates a high performing system in terms of energy consumption Several energy efficiency measures can reduce directly the energy consumption in a water supply system enabling significant reductions of GHG emissions these are inter alia\n",
      "\n",
      "doc2vec: Adjustments to thresholds energy thresholds should be revisited on a fiveyear basis in order to reflect state of the art research and progress on decarbonisation efforts Particularly the emission threshold for electricity generation should be reduced every five years\n",
      "--------------------\n",
      "What are examples of sludge treatments?\n",
      "tfidf: No threshold applies Rationale Sewage sludge is a byproduct of wastewater treatment with organic and inorganic content The organic content of the sludge is subject of decomposition which might occur under controlled circumstances in sludge treatment installations or under uncontrolled circumstances in the final disposal with significant GHG emissions mainly methane Anaerobic Digestion AD and in some cases aerobic digestion are examples of sludge treatments In AD microorganisms decompose the organic matter of the sludge in the absence of oxygen and produce methanerich biogas The primary climate mitigation effect of biogas is its use a source of renewable energy in multiple forms and applications displacing fossil fuels 297 As an additional contribution to climate mitigation the sludge can be turned into a recyclable product eg as fertilizer substituting synthetic fertilizers\n",
      "\n",
      "doc2vec: No threshold applies Rationale Sewage sludge is a byproduct of wastewater treatment with organic and inorganic content The organic content of the sludge is subject of decomposition which might occur under controlled circumstances in sludge treatment installations or under uncontrolled circumstances in the final disposal with significant GHG emissions mainly methane Anaerobic Digestion AD and in some cases aerobic digestion are examples of sludge treatments In AD microorganisms decompose the organic matter of the sludge in the absence of oxygen and produce methanerich biogas The primary climate mitigation effect of biogas is its use a source of renewable energy in multiple forms and applications displacing fossil fuels 297 As an additional contribution to climate mitigation the sludge can be turned into a recyclable product eg as fertilizer substituting synthetic fertilizers\n",
      "--------------------\n",
      "How is the process of anaerobic digestion?\n",
      "tfidf: For Anaerobic Digestion of Biowaste and Sewage Sludge refer to activities 55 and 53 respectively Any other anaerobic digestion of organic material not covered under sections 53 and 55 is eligible provided that  methane leakage from relevant facilities eg for biogas production and storage energy generation digestate storage is controlled by a monitoring plan\n",
      "\n",
      "doc2vec: 549 For definition of biowaste refer to Directive EU 2018851 of the European Parliament and of the Council of 30 May 2018 amending Directive 200898EC on waste Article 13b 550 httpseurlexeuropaeulegalcontentENTXTPDFuriCELEX32018D1147fromEN 551\n",
      "--------------------\n",
      "How is reforestation defined?\n",
      "tfidf: Reforestation Reforestation is defined as the reestablishment of forest through planting andor deliberate seeding on land classified as forest It implies no change of land use includes plantingseeding of temporarily unstocked forest areas as well as plantingseeding of areas with forest cover It includes coppice from trees that were originally planted or seeded69 The FAO FRA definition of reforestation excludes natural regeneration However the Taxonomy recognises the importance of natural regeneration to the increased carbon sink and stock potential provided by forests in general It is therefore included explicitly within this context in line with the FAO FRA definition of naturally regenerating forest70 In the context of the Taxonomy the category reforestation applies in cases following extreme events wind throws fires etc and not as part of normal legally binding obligation to reforest after harvesting\n",
      "\n",
      "doc2vec: Landscape management level may be used to emphasize that the goal to preserve conservation status for different species is at a scale above the single forest stand 444 This criterion should be considered in combination with criterion 3 of the mitigation criteria to disclose through a forest management plan or equivalent\n",
      "--------------------\n",
      "What is the threshold of emssion for inland passenger water transport?\n",
      "tfidf: Users of the Taxonomy should identify and explain which criteria they are responding to Do no significant harm assessment The main potential significant harm to other environmental objectives from the operation of inland passenger and freight water transport are summarised as follows\n",
      "\n",
      "doc2vec: The threshold of 50 lower than average reference CO2 emissions of HDVs ensures that the carbon intensity remains similar to criteria for eligible road freight vehicles with a review in 2025 to assess technology developments in the freight transport sector The Heavy Duty CO2 Regulation uses a g CO2km metric To convert this to a g CO2tonnekm metric the average payload for the road freight vehicles should be applied Once reference value data is available it is expected that the taxonomy will specify CO2etkm threshold values Rationale The carbon intensity of freight rail even if diesel is in most cases significantly lower than road freight transport rail freight transport at least meeting the threshold proposed in the road transport HDV criteria is eligible Average direct emissions for diesel rail is in the range of 1840 g CO2\n",
      "--------------------\n",
      "What are the requirements of reporting for electricity generation from natural gas where there might be fugative emissions?\n",
      "tfidf: Scope 1 all direct emissions related to the production the processs direct emissions and the emissions due to fuel use for onsite energy production Scope 2 Electricity consumption for electrolysis process and related emissions from the generation of the electricity used\n",
      "\n",
      "doc2vec: Precision and multiphase feeding techniques where the nutrient requirements of groups of animals or individual animals are targeted in feed formulation This can reduce nitrogen excretion and subsequent N2O emissions from manure and also increase feed efficiency in general reducing the feed related upstream emissions\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for ic,(question, context)  in enumerate(vector_representations):\n",
    "    print(question[0])\n",
    "    print(f\"tfidf: {context}\\n\\ndoc2vec: {doc2vec_similarities[ic][1]}\")\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d3d7c",
   "metadata": {},
   "source": [
    "# 3. Set-up Transformers for Question-Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbb8e6a",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Get familiar with using the Hugging Face library for applied purposes\n",
    "The main goal is to extract the answer given a question-paragr## aph tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c860383b",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Either of the cases will require pointing to an existing pretrained or, in our case, fine-tuned model. You can find a library of pretrained and fine-tuned models at Hugging Face Models. Notice that some of the models are quite large and perhaps will either not work or slow your computer down. A smaller model that could be a good starting point is distilbert-base-uncased-distilled-squad.\n",
    "\n",
    "- There are other libraries you could use to develop a Question-Answering model. However, for this project we want to focus on the Hugging Face transformers since they are already pretrained and fine tuned. They also provide a very simple interface to set up and use the model.\n",
    "\n",
    "- There are two different methods to use the transformers library. There are pros and cons for both, but for the purposes of this project it does not make any difference which one you choose.\n",
    "\n",
    "- We will only use exact matches as an evaluation metric, as mentioned above. This is basically a count of the number of data points that the model predicts correctly over the total number of data points. A regular string match should be sufficient for the purpose of this project. Again, you do not need to use the entire dataset since it can take a lot of computational power, but rather sample some data from it (perhaps 1000 data points or so).m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7fdea",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- Real-World Natural Language Processing by Masato Hagiwara Chapter 9, section 3, “Case study 1: Sentiment analysis with BERT,” provides an example of using the Hugging Face transformers library.\n",
    "\n",
    "\n",
    "- Taming Text by Grant S. Ingersoll, Thomas S. Morton, and Andrew L. Farris Chapter 8, “Building an example question answering system,” is helpful if you want to understand the theory behind building a question answering system.\n",
    "\n",
    "\n",
    "- Natural Language Processing in Action by Hobson Lane, Cole Howard, and Hannes Hapke Chapter 10, “Sequence-to-sequence models and attention,” contains theoretical background on how transformers work.\n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- HuggingFace Transformers library documentation will be used for the question answering.\n",
    "\n",
    "- Question answering tutorial https://huggingface.co/transformers/usage.html#extractive-question-answering – Note that we will use PyTorch for this project.\n",
    "\n",
    "- Information about the Stanford question-answer dataset https://rajpurkar.github.io/SQuAD-explorer/, as well as a list of how different algorithms perform on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb23aa31",
   "metadata": {},
   "source": [
    "## Help\n",
    "\n",
    "- When setting up pipeline, you can point to a given model and tokenizer by including those as parameters, for example:\n",
    "\n",
    "- qamodel = pipeline(\"question-answering\", model=MODEL, tokenizer=MODEL, device=-1).\n",
    "\n",
    "- The structure of SQuAD is a set of paragraphs—each paragraph has a set of questions and a set of answers. It might be good to extract tuples of these to make the evaluation easier. For the evaluation, you can just see how often there is an exact match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "65a89fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "with open(\"data/dev-v2.0.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def get_question_answers_context(data):\n",
    "    # this function should provide tuples of question, answer and context from the data\n",
    "    tuples = []\n",
    "    for i in range(len(data['data'])):\n",
    "        for j in range(len(data['data'][i]['paragraphs'])):\n",
    "            tuples.extend(data['data'][i]['paragraphs'][j]['qas'])\n",
    "    return tuples\n",
    "\n",
    "qac = random.sample(get_question_answers_context(data), TEST_SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f2959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8610a935",
   "metadata": {},
   "source": [
    "## Import the pipeline class.\n",
    "\n",
    "This will be more straightforward and you will get less exposure to the components of the transformer than in the previous milestone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "326246a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857325d",
   "metadata": {},
   "source": [
    "## Set up the model and point to an existing pretrained and fine-tuned model. \n",
    "\n",
    "(See the notes for more detail.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "13d0b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"distilbert-base-uncased-distilled-squad\"\n",
    "TEST_SAMPLE_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0e34ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "with open(\"data/dev-v2.0.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def get_question_answers_context(data):\n",
    "    # this function should provide tuples of question, answer and context from the data\n",
    "    tuples = []\n",
    "    for data_index in data['data']:\n",
    "        for para_index in data_index['paragraphs']:\n",
    "            for q_index in para_index['qas']:\n",
    "                answers = [answer[\"text\"] for answer in q_index[\"answers\"]]\n",
    "                tuples.append((q_index['question'], answers, para_index['context']))\n",
    "    return tuples\n",
    "\n",
    "qac = random.sample(get_question_answers_context(data), TEST_SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3f276",
   "metadata": {},
   "source": [
    "## Use the SQuAD dev dataset to test how the different models are performing. \n",
    "\n",
    "The metric you will need to set up here is an exact match metric, which means you just need to see whether the predicted text is exactly the same as the answer provided in the dataset. You do not need to use the entire dataset, but make sure to evaluate a sample to ensure that the model performs well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "af806b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_em_scores(qac, qa_model):\n",
    "    score = []\n",
    "    for question, answers, context in qac:\n",
    "        answer = qa_model(question=question, context=context)\n",
    "        if not answer and not answers:\n",
    "            score.append(True)\n",
    "        else:\n",
    "            score.append(any([answer.lower()==ans.lower() for ans in answers]))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "dfce04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qamodel = pipeline(\"question-answering\", model=MODEL, tokenizer=MODEL, device=-1)\n",
    "\n",
    "def get_answer_pipeline(question, context):\n",
    "    answer = qamodel(question=question, context=context)\n",
    "    if answer[\"score\"] < 0.6:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return answer[\"answer\"].rstrip(\".\").rstrip(\",\").lstrip(\"(\").rstrip(\")\").rstrip(\".\").strip(\"'\").strip(\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5a3aa0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534\n"
     ]
    }
   ],
   "source": [
    "scores = get_em_scores(qac, get_answer_pipeline)\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b8fef",
   "metadata": {},
   "source": [
    "## Explore a few different models and evaluate which performs the best. \n",
    "\n",
    "For this project, we will only use exact matches as an evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fd166233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL)\n",
    "\n",
    "\n",
    "def get_answer(question, context):\n",
    "    inputs = tokenizer.encode_plus(question, \n",
    "                                   context, \n",
    "                                   add_special_tokens=True, \n",
    "                                   return_tensors=\"pt\", \n",
    "                                   max_length=tokenizer.max_len_sentences_pair, truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        answer_start_scores, answer_end_scores = model.(**inputs)\n",
    "        print(answer_start_scores, answer_end_scores)\n",
    "        answer_start_scores, answer_end_scores = answer_start_scores.cpu().numpy(), answer_end_scores.cpu().numpy()\n",
    "        \n",
    "    answer_start = np.argmax(\n",
    "        answer_start_scores\n",
    "    )  # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = np.argmax(\n",
    "        answer_end_scores\n",
    "    ) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "    \n",
    "    # Normalize logits and spans to retrieve the answer\n",
    "    start_ = np.exp(answer_start_scores - np.log(np.sum(np.exp(answer_start_scores), axis=-1, keepdims=True)))\n",
    "    end_ = np.exp(answer_end_scores - np.log(np.sum(np.exp(answer_end_scores), axis=-1, keepdims=True)))\n",
    "    score = np.mean([start_[0][answer_start], end_[0][answer_end-1]])\n",
    "    \n",
    "    if score > 0.9:\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "        return answer\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2ffc2",
   "metadata": {},
   "source": [
    "## Bonus: Use the question and paragraph pairs from the previous milestone as input to allow the model to predict the location of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1a5915e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = get_em_scores(qac, get_answer)\n",
    "# print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6a4ae",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Bonus: If you want to get a better understanding of setting up the model, you can import the AutoTokenizer and AutoModelForQuestionAnswering classes from the transformers library.\n",
    "\n",
    "- Here you will get more insight into the structure of the pipeline—the two classes are the two main parts of the transformers architecture.\n",
    "\n",
    "\n",
    "- One is the tokenization model which tokenizes both the question and the context (paragraph), and the second is the Question-Answering model which predicts where in the sequenced tokens of the context the answer starts and ends, given the question tokens as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e4780",
   "metadata": {},
   "source": [
    "# M4 Build an End-to-End Question-Answering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38851ee1",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Integrate the previous milestones into an end-to-end application for question answering on the EU taxonomy for sustainable finance corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb5a89d",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- The key here is to be able to clean up the code and test out the ensemble of the models to get the answers from the entire corpus.\n",
    "\n",
    "\n",
    "- The goal of this milestone is to wrap up all your code and plug the functions in to a prebuilt template in order to visualize the application.\n",
    "\n",
    "Here is the list of questions and potential answers for this project:\n",
    "\n",
    "- What fuel is used for manufacturing of chlorine?\n",
    "    A: Electricity\n",
    "\n",
    "\n",
    "- What metric is used for evaluating emission?\n",
    "    A: gCO2e\n",
    "\n",
    "\n",
    "- How can carbon emission of the processes of cement clinker be reduced?\n",
    "    A: The use of biomass and waste materials as fuels in cement kilns\n",
    "\n",
    "\n",
    "- How is the Weighted Cogeneration Threshold calculated?\n",
    "    A: The relative production of heat and power\n",
    "\n",
    "\n",
    "- What is carbon capture and sequestration?\n",
    "    A: A key technology for the decarbonisation of Europe\n",
    "\n",
    "\n",
    "- What stages does CCS consist of?\n",
    "    A: Capture, transport and storage\n",
    "\n",
    "\n",
    "- What should be the average energy consumption of a water supply system?\n",
    "    A: 05 kWh per cubic meter\n",
    "\n",
    "\n",
    "- What are sludge treatments?\n",
    "    A: Methane Anaerobic Digestion and in some cases aerobic digestion\n",
    "\n",
    "\n",
    "- What is the process of anaerobic digestion?\n",
    "    A: Microorganisms decompose the organic matter of the sludge in the absence of oxygen\n",
    "\n",
    "\n",
    "- How is reforestation defined?\n",
    "    A: Re-establishment of forests\n",
    "\n",
    "\n",
    "- What is the threshold of emission for inland passenger water transport?\n",
    "    A: 50gCO2e/pkm\n",
    "\n",
    "\n",
    "- What are the requirements of reporting for electricity generation from natural gas where there might be fugitive emissions?\n",
    "    A: full life cycle assessment of fugitive emissions\n",
    "\n",
    "\n",
    "\n",
    "- Note that the questions might not have exact answers and these are just a few examples. Thus we cannot do a fair quantitative evaluation. However, you can get a feel for the model and do a somewhat qualitative evaluation. This project provides a good understanding of how you can implement the first version of a Question-Answering model without any domain-specific labeled data, which is a quite common problem faced in the industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2dcbac",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "- In this template app  https://github.com/MatteusT/QAtemplate you can plug in functions and use the GUI for Question-Answering model testing. It contains instructions for use.\n",
    "\n",
    "\n",
    "- General information about the Django platform https://docs.djangoproject.com/en/3.0/ used in the application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f55c79",
   "metadata": {},
   "source": [
    "## Help\n",
    "\n",
    "You will need to have just two main functions ready. You will integrate them into the code from QAtemplate. The two functions are:\n",
    "\n",
    "- A function to find the paragraph most relevant to the question\n",
    "\n",
    "    def get_context(question):\n",
    "    ...\n",
    "    return paragraph\n",
    "\n",
    "\n",
    "- A function that returns the answer from input of a paragraph and the given question\n",
    "\n",
    "    def get_answer_pipeline(question, context):\n",
    "    ...\n",
    "    return answer```\n",
    "\n",
    "\n",
    "You will also need a function to process the document and return the paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f67a9e",
   "metadata": {},
   "source": [
    "## Create a function from the findings in Milestone 1—a function that inputs a file path and returns a list of paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b7c43854",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vector_corpus = vectorizer.fit_transform(df[\"paragraph\"])\n",
    "\n",
    "\n",
    "def get_context(question):\n",
    "    q_v = vectorizer.transform(question)\n",
    "    lk_rank = linear_kernel(q_v, vector_corpus).flatten()\n",
    "    return df[\"paragraph\"][lk_rank.argsort()[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b4c8b",
   "metadata": {},
   "source": [
    "## Create a function from the findings in Milestone 2—a function that inputs a list of paragraphs and a question and returns a ranked list with the top n paragraphs that are most similar to the question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "16f67a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "MODEL = \"distilbert-base-uncased-distilled-squad\"\n",
    "qamodel = pipeline(\"question-answering\", model=MODEL, tokenizer=MODEL, device=-1)\n",
    "\n",
    "def get_answer_pipeline(question, context):\n",
    "    answer = qamodel(question=question, context=context)\n",
    "    return answer[\"answer\"].rstrip(\".\").rstrip(\",\").lstrip(\"(\").rstrip(\")\").rstrip(\".\").strip(\"'\").strip(\":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab96eced",
   "metadata": {},
   "source": [
    "## Create a function of the findings in Milestone 3—a function that inputs a string consisting of a question and a list of paragraphs and returns a list of strings containing the extractive answers from those paragraphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "42098d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What fuel is used for manufacturing of chlorine?\n",
      "\n",
      "soda ash214\n",
      "\n",
      "Rationale The manufacturing process of carbon black accounts for approximately 34 of the GHG emissions from the chemical sector while the manufacturing of soda ash accounts for 15 of the emissions 212 The manufacturing process of chlorine is extremely energyintensive with chloralkali process accounting for 17 of total electrical consumption of the European chemical and petrochemical industry213 Reducing the manufacturing emissions for carbon black and soda ash and improving energy efficiency in the manufacturing of chlorine can positively contribute to the mitigation objective Moreover it is recognised that soda ash used in double glazing can enhance building efficiency gains The absolute performance approach has been proposed in order to identify the maximum acceptable carbon intensities of the manufacturing processes of carbon black and soda ash that the activities should comply with in order to be able to substantially contribute to the mitigation objective For the manufacturing of chlorine a process that uses electricity to fuel the electrolysis process the absolute performance approach has been proposed in order to identify the energy intensity threshold In addition to complying with the energy efficiency threshold the process shall be based on low carbon electricity ETS product benchmarks have been selected as thresholds for the manufacturing of carbon black and soda ash They reflect the average performance of the 10 most efficient installations in a sector Emissions covered  Scope 1 All direct emissions related to the production the process direct emissions and the emissions due to fuel use for energy production  Note on the electricity According to the methodology to calculate ETS benchmarks emissions from electricity are considered where direct emissions and indirect emissions from electricity are to a certain level interchangeable as is the case for carbon black but not for soda ash214 For chlorine the value corresponding to an efficient level of electricity consumption was selected as the threshold given that the main source of energy used for the production of chlorine is electricity and by improving the energy efficiency of the process as well as using low carbon electricity sources the activity can substantially contribute to the climate change mitigation objective httpseurlexeuropaeuLexUriServLexUriServdouriOJC201238700050013ENPDF httpsepubwupperinstorgfrontdoordeliverindexdocId6478file6478_Lechtenboehmerpdf\n",
      "----------------------------------------------------------------------------------------------------\n",
      "What metric is used for evaluating emission?\n",
      "\n",
      "g CO2km\n",
      "\n",
      "\f",
      "transport sector The Heavy Duty CO2 Regulation uses a g CO2km metric To convert this to a g CO2tonnekm metric the average payload for the road freight vehicles should be applied Once reference value data is available it is expected that the taxonomy will specify CO2etkm threshold values\n",
      "----------------------------------------------------------------------------------------------------\n",
      "How can carbon emission of the processes of cement clinker be reduced?\n",
      "\n",
      "lower than the value of the related EUETS benchmark\n",
      "\n",
      "Thresholds for cement Clinker A are applicable to plants that produce clinker only and do not produce finished cement All other plants need to meet the thresholds for cement or alternative binder A Cement clinker Specific emissions calculated according to the methodology used for EUETS benchmarks associated to the clinker production processes are lower than the value of the related EUETS benchmark As of February 2020 the EUETS benchmark value for cement clinker manufacturing is 0766 tCO2et of clinker198 B Cement Specific emissions associated to the clinker and cement production processes are lower than 0498 tCO2et of cement or alternative binder 199\n",
      "----------------------------------------------------------------------------------------------------\n",
      "How is the Weighted Cogeneration Threshold calculated?\n",
      "\n",
      "Generation of heatcool threshold\n",
      "\n",
      "Cogeneration of Heat and Power is covered under Construction and operation of a facility used for cogeneration of heatcooling and Power threshold Generation of heatcool is covered under the Generation of heatcool threshold\n",
      "----------------------------------------------------------------------------------------------------\n",
      "What is carbon capture and sequestration?\n",
      "\n",
      "chemicalstechnologies used to capture carbon 1 Mitigation\n",
      "\n",
      "Users of the Taxonomy should identify and explain which criteria they are responding to Do no significant harm assessment The main environmental impacts associated with Capture of Anthropogenic Emissions are due to chemicalstechnologies used to capture carbon 1 Mitigation\n",
      "----------------------------------------------------------------------------------------------------\n",
      "What stages does CCS consist of?\n",
      "\n",
      "capture transport and storage CO 2 transport and storage\n",
      "\n",
      "\f",
      "low carbon economy and with the inbuilt flexibility on options for demonstrating compliance they can be applied globally Impact of these proposals The activities do not impose major additional implementation costs on the stakeholders because as explained for most of them  except water collection treatment and supply  the climate mitigation effects are an inherent result of key characteristics of the correspondent business models and thus should come along without significant further cost Considering water collection treatment and supply additional investments may be necessary in order to reach certain thresholds however the corresponding costs may partially be equalized by cost savings from higher energy efficiency There should be no systematic distortive effect of the activities on the number and competitive position of the companies in the corresponding sectors The overall sectoral technological impact will depend on the state of the water wastewater and waste management in each Member State in terms of eg regional coverage of different management technologies Outside of the EU the technological impact could be even greater if the state of the sector in an individual country or region is below that of the EU Clear additional beneficial environmental effects can be assumed for eg water circular economy and pollution Employment effects should be positive and further beneficial economic impacts are induced through increased investments and the demand for consumer goods Why carbon capture and sequestration CCS is included in the Taxonomy Carbon capture and sequestration CCS is a key technology for the decarbonisation of Europe It is included in all pathways presented by the European Commission in its LongTerm Strategic Vision document and is relied upon heavily in threeoutoffour scenarios outlined by the IPCC in the Special Report on 15 Degrees A typical CCS chain consists of three main stages capture transport and storage CO 2 transport and storage are established and proven processes with decades of operation and wellestablished regulation here in Europe The Technical Expert Group has developed criteria to define the eligibility of facilities used to capture carbon dioxide directly from the atmosphere and separately to capture carbon dioxide directly from anthropogenic activities CCS can be eligible in any sectoractivity if it enables that primary activity to operate in compliance with the threshold  for example steel cement or electricity production\n",
      "----------------------------------------------------------------------------------------------------\n",
      "What should be the average energy consumption of a water supply system?\n",
      "\n",
      "05 kwh per cubic meter\n",
      "\n",
      "\f",
      "The unit of measurement is the Infrastructure Leakage Index ILI 296 the target value of low leakage is an ILI of 15 Rationale The water supply sector is a wide and varied sector with very different performance conditions depending on the water source the necessary treatment the topography of the supplied area the length of the network etc ILI and kwhm3 supplied are chosen as parameters in order to measure the efficiency of a water supply system An average energy consumption of a water supply system of 05 kwh per cubic meter billedunbilled authorized water supply indicates a high performing system in terms of energy consumption Several energy efficiency measures can reduce directly the energy consumption in a water supply system enabling significant reductions of GHG emissions these are inter alia\n",
      "----------------------------------------------------------------------------------------------------\n",
      "What are examples of sludge treatments?\n",
      "\n",
      "aerobic digestion\n",
      "\n",
      "No threshold applies Rationale Sewage sludge is a byproduct of wastewater treatment with organic and inorganic content The organic content of the sludge is subject of decomposition which might occur under controlled circumstances in sludge treatment installations or under uncontrolled circumstances in the final disposal with significant GHG emissions mainly methane Anaerobic Digestion AD and in some cases aerobic digestion are examples of sludge treatments In AD microorganisms decompose the organic matter of the sludge in the absence of oxygen and produce methanerich biogas The primary climate mitigation effect of biogas is its use a source of renewable energy in multiple forms and applications displacing fossil fuels 297 As an additional contribution to climate mitigation the sludge can be turned into a recyclable product eg as fertilizer substituting synthetic fertilizers\n",
      "----------------------------------------------------------------------------------------------------\n",
      "How is the process of anaerobic digestion?\n",
      "\n",
      "a monitoring plan\n",
      "\n",
      "For Anaerobic Digestion of Biowaste and Sewage Sludge refer to activities 55 and 53 respectively Any other anaerobic digestion of organic material not covered under sections 53 and 55 is eligible provided that  methane leakage from relevant facilities eg for biogas production and storage energy generation digestate storage is controlled by a monitoring plan\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is reforestation defined?\n",
      "\n",
      "the reestablishment of forest\n",
      "\n",
      "Reforestation Reforestation is defined as the reestablishment of forest through planting andor deliberate seeding on land classified as forest It implies no change of land use includes plantingseeding of temporarily unstocked forest areas as well as plantingseeding of areas with forest cover It includes coppice from trees that were originally planted or seeded69 The FAO FRA definition of reforestation excludes natural regeneration However the Taxonomy recognises the importance of natural regeneration to the increased carbon sink and stock potential provided by forests in general It is therefore included explicitly within this context in line with the FAO FRA definition of naturally regenerating forest70 In the context of the Taxonomy the category reforestation applies in cases following extreme events wind throws fires etc and not as part of normal legally binding obligation to reforest after harvesting\n",
      "----------------------------------------------------------------------------------------------------\n",
      "What is the threshold of emssion for inland passenger water transport?\n",
      "\n",
      "no significant harm\n",
      "\n",
      "Users of the Taxonomy should identify and explain which criteria they are responding to Do no significant harm assessment The main potential significant harm to other environmental objectives from the operation of inland passenger and freight water transport are summarised as follows\n",
      "----------------------------------------------------------------------------------------------------\n",
      "What are the requirements of reporting for electricity generation from natural gas where there might be fugative emissions?\n",
      "\n",
      "Scope 2 Electricity consumption for electrolysis process and related emissions\n",
      "\n",
      "Scope 1 all direct emissions related to the production the processs direct emissions and the emissions due to fuel use for onsite energy production Scope 2 Electricity consumption for electrolysis process and related emissions from the generation of the electricity used\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    context = get_context(question)\n",
    "    answer = get_answer_pipeline(question, context)\n",
    "    print(f\"{question[0]}\\n\\n{answer}\\n\\n{context}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80baa286",
   "metadata": {},
   "source": [
    "## Integrate the functions into the repository https://github.com/MatteusT/QAtemplate and follow the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb223390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cdbad9d",
   "metadata": {},
   "source": [
    "## Bonus: Get the django-app working with your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b20d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
