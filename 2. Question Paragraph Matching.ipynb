{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4ae722",
   "metadata": {},
   "source": [
    "# M1 Extracting Paragraphs from the EU Taxonomy Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bafd6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import textract\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9afb7",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Process the EU sustainable finance taxonomy PDF file and extract and clean all the paragraphs in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f7ca7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Download the EU sustainable finance taxonomy PDF from Taxonomy Report: Technical Annex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbab343",
   "metadata": {},
   "source": [
    "## Load the EU sustainable finance taxonomy PDF file using the textract library and decode it. \n",
    "\n",
    "Look through the text to ensure that you have got all the text and that the decoding did not produce any bad characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "52dfc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = textract.process('EUtaxonomy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c5902a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "167913a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = textract.process('EUtaxonomy.pdf', method='pdfminer').decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d1a94",
   "metadata": {},
   "source": [
    "## Use regular expressions to split the paragraphs and clean the text. \n",
    "\n",
    "The loaded text will be in raw format and will need to be segmented into paragraphs. These paragraphs will also need to be cleaned by removing newline characters and other characters that do not bring any semantic value to the paragraph (such as tabs or bullet points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6ab9821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320996"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "173001cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Updated methodology & Updated Technical Screening Criteria\\n- 1-\\n\\nMarch 2020\\n\\n\\x0cAbout this report\\nThis document includes an updated Part B: Methodology from the June 2019 report and an updated Part\\nF: Full list of technical screening criteria. The other original sections from the June 2019 report can be\\nfound as labelled in the June 2019 report.\\nPART A\\n\\nExplanation of the Taxonomy approach. This section sets out the role and importance of\\nsustainable finance in Europe from a policy and investment perspective, the rationale for\\nthe development of an EU Taxonomy, the daft regulation and the mandate of the TEG.\\n\\nPART B\\n\\nMethodology. This explains the methodologies for developing technical screening\\ncriteria for climate change mitigation objectives, adaptation objectives and ‘do no\\nsignificant harm’ to other environmental objectives in the legislative proposal.\\nThis has been updated since 2019.\\n\\nPART C\\n\\nTaxonomy user and use case analysis. This section provides practical guidance to\\npotentia'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3e007ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = re.split(r\"\\s*?\\n\\s*?\\n\\s*?\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2367222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8984"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fc034422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x0cAbout this report\\nThis document includes an updated Part B: Methodology from the June 2019 report and an updated Part\\nF: Full list of technical screening criteria. The other original sections from the June 2019 report can be\\nfound as labelled in the June 2019 report.\\nPART A'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "907016f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explanation of the Taxonomy approach. This section sets out the role and importance of\\nsustainable finance in Europe from a policy and investment perspective, the rationale for\\nthe development of an EU Taxonomy, the daft regulation and the mandate of the TEG.'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d6b8a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_paragraph(text):\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"  \", \" \").strip(\" \")\n",
    "    return re.sub(r'[^\\w\\s]', '', text).strip(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da95d3",
   "metadata": {},
   "source": [
    "## Store the paragraphs in a DataFrame with the column “paragraph” using the pandas library and save the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "202c2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=paragraphs)\n",
    "df.columns=['paragraph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e078896c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Updated methodology &amp; Updated Technical Screen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>March 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>About this report\\nThis document includes an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explanation of the Taxonomy approach. This sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PART B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  Updated methodology & Updated Technical Screen...\n",
       "1                                         March 2020\n",
       "2  \n",
       "About this report\\nThis document includes an ...\n",
       "3  Explanation of the Taxonomy approach. This sec...\n",
       "4                                             PART B"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "53634d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['paragraph'] = df['paragraph'].apply(clean_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "81f01859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Updated methodology  Updated Technical Screeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>March 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>About this report This document includes an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explanation of the Taxonomy approach This sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PART B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  Updated methodology  Updated Technical Screeni...\n",
       "1                                         March 2020\n",
       "2  \n",
       "About this report This document includes an u...\n",
       "3  Explanation of the Taxonomy approach This sect...\n",
       "4                                             PART B"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ab8d169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "12ff1b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Updated methodology  Updated Technical Screening Criteria  1',\n",
       "       'March 2020',\n",
       "       '\\x0cAbout this report This document includes an updated Part B Methodology from the June 2019 report and an updated Part F Full list of technical screening criteria The other original sections from the June 2019 report can be found as labelled in the June 2019 report PART A',\n",
       "       ..., 'Wildfire', '5', '\\x0c'], dtype=object)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.paragraph.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606fe50",
   "metadata": {},
   "source": [
    "# M2 Question Paragraph Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "40b08ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522e174",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Build a text vectorizer that finds the best matching paragraph for the provided set of questions and qualitatively evaluates the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d93fc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45544c",
   "metadata": {},
   "source": [
    "## Initiate a TF-IDF model trained on the paragraphs from the previous milestone by using the TfidfVectorizer class from the scikit-learn library. \n",
    "\n",
    "This model will provide a representation for each paragraph or each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "055088d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c0e470d6",
   "metadata": {},
   "outputs": [],
   "source": [
    " X = vectorizer.fit_transform(df['paragraph'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "519132a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '00295', '0045', ..., 'zurich', 'zwickel', 'μgnm3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d3e55cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8984, 7424)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe32f4",
   "metadata": {},
   "source": [
    "## Transform all the paragraphs into representations and calculate a distance in the representation space between each question and all the paragraphs. \n",
    "\n",
    "The distance can be calculated using the linear_kernel function from the scikit-learn library. Sort all the distances and match the paragraph that best corresponds to each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7ad2074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    [\"What fuel is used for manufacturing of chlorine?\"],\n",
    "    [\"What metric is used for evaluating emission?\"],\n",
    "    [\"How can carbon emission of the processes of cement clinker be reduced?\"],\n",
    "    [\"How is the Weighted Cogeneration Threshold calculated?\"],\n",
    "    [\"What is carbon capture and sequestration?\"],\n",
    "    [\"What stages does CCS consist of?\"],\n",
    "    [\"What should be the average energy consumption of a water supply system?\"],\n",
    "    [\"What are examples of sludge treatments?\"],\n",
    "    [\"How is the process of anaerobic digestion?\"],\n",
    "    [\"How is reforestation defined?\"],\n",
    "    [\"What is the threshold of emssion for inland passenger water transport?\"], \n",
    "    [\"What are the requirements of reporting for electricity generation from natural gas where there might be fugative emissions?\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0acc27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "kernel = linear_kernel(X)\n",
    "# Iterate through the questions and transform each of them to their vector representation. \n",
    "# Then use linear_kernel to get the distances and get the smallest one.\n",
    "question_vectorizer = TfidfVectorizer()\n",
    "vector_representations = []\n",
    "\n",
    "for question in questions:\n",
    "    vec_rep = question_vectorizer.fit_transform(question)\n",
    "    vector_representations.append(vec_rep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "77ea9a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.32988537, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.32988537, 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_kernel(X)\n",
    "# linear_kernel(vector_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea133dc3",
   "metadata": {},
   "source": [
    "## Bonus: Train a Doc2vec model with the paragraphs using the Doc2vec model provided by the gensim library. \n",
    "\n",
    "Similar to the TF-IDF model, Doc2vec provides a representation for the paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53698f",
   "metadata": {},
   "source": [
    "## Bonus: Given the representation of the paragraphs, use the most_similar method in the gensim library, which uses cosine distance to get the paragraphs that best match the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8657a1",
   "metadata": {},
   "source": [
    "## Bonus: Evaluate the two different methods for matching questions to paragraphs and pick the better performing one to use in the next milestone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d9e5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
